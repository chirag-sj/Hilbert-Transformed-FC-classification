{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.covariance import OAS\n",
    "from scipy.signal import hilbert\n",
    "# from scipy.fftpack import hilbert as fhil"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the dictionary: dict_keys(['timeseires', 'label', 'corr', 'pcorr', 'site'])\n",
      "Timeseries: (1009, 200, 100)\n",
      "Labels: (1009,)\n",
      "Correlation: (1009, 200, 200)\n",
      "PCorr: (1009, 200, 200)\n",
      "Site: (1009,)\n"
     ]
    }
   ],
   "source": [
    "abide_dict = np.load('../../dataset/abide.npy', allow_pickle=True).item()\n",
    "#check the keys in the dictionary\n",
    "print('Keys in the dictionary:',abide_dict.keys())\n",
    "print('Timeseries:',abide_dict['timeseires'].shape)\n",
    "print('Labels:',abide_dict['label'].shape)\n",
    "print('Correlation:',abide_dict['corr'].shape)\n",
    "print('PCorr:',abide_dict['pcorr'].shape)\n",
    "print('Site:',abide_dict['site'].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance Matrix Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_covariance_matrix(data):\n",
    "    \"\"\"\n",
    "    Calculate the normalized covariance matrix for time series data.\n",
    "    \n",
    "    Args:\n",
    "        data (ndarray): A 2D numpy array containing the time series data.\n",
    "        \n",
    "    Returns:\n",
    "        ndarray: The normalized covariance matrix.\n",
    "    \"\"\"\n",
    "    # Calculate the covariance matrix\n",
    "    data = hilbert(data) #apply hilbert transform\n",
    "    cov_matrix = np.cov(data.T, rowvar=False)\n",
    "    \n",
    "    # Calculate the diagonal matrix of standard deviations\n",
    "    std_devs = np.sqrt(np.diag(cov_matrix))\n",
    "    std_dev_matrix = np.diag(std_devs)\n",
    "    \n",
    "    # Calculate the inverse of the standard deviation matrix\n",
    "    inv_std_dev_matrix = np.linalg.pinv(std_dev_matrix)\n",
    "    \n",
    "    # Calculate the normalized covariance matrix\n",
    "    normalized_cov_matrix = np.dot(inv_std_dev_matrix, np.dot(cov_matrix, inv_std_dev_matrix))\n",
    "    \n",
    "    return normalized_cov_matrix\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tangent Space based SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1009, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "fc_ts = abide_dict['timeseires']\n",
    "fc_cov = []\n",
    "for i in range(fc_ts.shape[0]):\n",
    "    fc_cov.append(normalized_covariance_matrix(fc_ts[i]))\n",
    "fc_cov = np.array(fc_cov)\n",
    "print(fc_cov.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7036746958277919"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# load your data\n",
    "X = np.imag(fc_cov) # EEG data, in format n_epochs x n_channels x n_times\n",
    "y = abide_dict['label'] # labels\n",
    "\n",
    "#train test split\n",
    "\n",
    "# build your pipeline\n",
    "covest = Covariances('oas')\n",
    "# reg_cov = covest.fit_transform(X)\n",
    "ts = TangentSpace()\n",
    "# ts_reg_cov = ts.fit_transform(reg_cov)\n",
    "svc = SVC(kernel='linear')\n",
    "clf = make_pipeline(covest, ts, svc)\n",
    "acc = cross_val_score(clf, X, y)\n",
    "acc.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temporal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
